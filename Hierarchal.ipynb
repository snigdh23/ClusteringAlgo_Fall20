{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching File Name and Number of Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = input(\"Please enter file name: \") #\"cho.txt\" \n",
    "k = int(input(\"Number of Clusters: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the Distance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(filePath, \"r\")\n",
    "lines = file.readlines()\n",
    "df1 = \"\"\n",
    "\n",
    "# splittng the line into individual data\n",
    "flag1 = 2\n",
    "for line in lines:\n",
    "    if(\" \" in line):\n",
    "        flag1 = 0\n",
    "    elif(\"\\t\" in line):\n",
    "        flag1 = 1\n",
    "    break\n",
    "\n",
    "if(flag1 == 0):\n",
    "    for line in lines:\n",
    "        df1 = pd.read_csv(filePath, sep = ' ', lineterminator = '\\n', header = None)\n",
    "elif(flag1 == 1):\n",
    "    for line in lines:\n",
    "        df1 = pd.read_csv(filePath, sep = '\\t', lineterminator = '\\n', header = None)\n",
    "else:\n",
    "    print(\"Data should be sperated by \\t or single space!\")\n",
    "    \n",
    "df2 = df1.copy()\n",
    "\n",
    "(rownum,colnum) = (df2.shape)\n",
    "distance_matrix = np.zeros((rownum, rownum))\n",
    "\n",
    "for i in range(rownum):\n",
    "    q1 = df2.iloc[i,2:].values\n",
    "    for j in range(rownum):\n",
    "        q2 = df2.iloc[j,2:].values\n",
    "        distance_matrix[i][j] = np.linalg.norm(q1-q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Agglomerative Clustering Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obvs = list(df2.iloc[:,0].values)\n",
    "dist_mat = distance_matrix.copy()\n",
    "\n",
    "#def hac(k,obvs,dist_mat,rownum,colnum)\n",
    "while(len(obvs)> k):\n",
    "    #min_dist = find_min(updist_mat, min_dist)\n",
    "    pos1 = 0\n",
    "    pos2 = 0\n",
    "    min_dist = 1000\n",
    "    for i in range(dist_mat.shape[0]):\n",
    "        for j in range(dist_mat.shape[0]):\n",
    "            if(dist_mat[i][j]==0):\n",
    "                break\n",
    "            elif(dist_mat[i][j]<min_dist):\n",
    "                    min_dist = dist_mat[i][j]\n",
    "                    (pos1,pos2) = (i,j)\n",
    "    \n",
    "    for i in range(dist_mat.shape[0]):        \n",
    "        dt1 = dist_mat[pos1][i]\n",
    "        dt2 = dist_mat[pos2][i]\n",
    "        min_dist1 = dt1\n",
    "        if(dt1 > dt2):\n",
    "            min_dist1 = dt2\n",
    "        else:\n",
    "            min_dist1 = dt1\n",
    "        dist_mat[pos1][i] = min_dist1\n",
    "        \n",
    "        dt3 = dist_mat[i][pos1]\n",
    "        dt4 = dist_mat[i][pos2]\n",
    "        min_dist2 = dt3\n",
    "        if(dt3 > dt4):\n",
    "            min_dist2 = dt4\n",
    "        else:\n",
    "            min_dist2 = dt3\n",
    "        dist_mat[i][pos1] = min_dist2\n",
    "        \n",
    "        \n",
    "    obvs[pos1] = list((obvs[pos1],obvs[pos2]))\n",
    "    dist_mat = np.delete(dist_mat, pos2, axis = 0)\n",
    "    dist_mat = np.delete(dist_mat, pos2, axis = 1)\n",
    "        \n",
    "    del obvs[pos2]\n",
    "    \n",
    "def listflatten(l):\n",
    "    clustered_obvs = []\n",
    "    if(type(l)==list):\n",
    "        for i in l:\n",
    "            clustered_obvs += listflatten(i) #recursively managing list within a list\n",
    "    else:\n",
    "        clustered_obvs.append(l)\n",
    "    return clustered_obvs\n",
    "\n",
    "clustered_obvs = []\n",
    "for i in obvs:\n",
    "    clustered_obvs.append(listflatten(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying the Clusters formed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clustered_obvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jaccard Co-eff and Rand Index Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obvs_truth = []\n",
    "for p1 in range(df2.shape[0]):\n",
    "    obvs_truth.append(0)\n",
    "cnt = 0    \n",
    "for i in range(len(clustered_obvs)):\n",
    "    for j in (clustered_obvs[i]):\n",
    "        obvs_truth[j-1] = (i+1)\n",
    "        \n",
    "grd_truth = list(df2.iloc[:,1].values)\n",
    "def cjr(ground_truth,observed_truth):\n",
    "    true_pos = 0\n",
    "    true_neg = 0\n",
    "    false_pos=0\n",
    "    false_neg=0\n",
    "    for i in range(df2.shape[0]):\n",
    "        for j in range(df2.shape[0]):\n",
    "            if ground_truth[i]==ground_truth[j]:\n",
    "                if observed_truth[i]==observed_truth[j]:\n",
    "                    true_pos=true_pos+1\n",
    "                else:\n",
    "                    false_neg=false_neg+1\n",
    "            elif ground_truth[i]!=ground_truth[j]:\n",
    "                if observed_truth[i]==observed_truth[j]:\n",
    "                    false_pos=false_pos+1\n",
    "                else:\n",
    "                    true_neg=true_neg+1\n",
    "    jaccard_coeff = (true_pos)/(true_pos+false_pos+false_neg)\n",
    "    rand_index = (true_pos+true_neg)/(true_pos+true_neg+false_pos+false_neg)\n",
    "    return jaccard_coeff,rand_index\n",
    "\n",
    "jaccard_coeff,rand_index = cjr(grd_truth,obvs_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization and Displaying the Jaccard & Rand Index Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_truth_nparr = np.asarray(obvs_truth)\n",
    "df3 = df2.copy()\n",
    "X_df = df3.iloc[:,2:].values\n",
    "ldf = pd.DataFrame(observed_truth_nparr,columns=[\"Label\"])\n",
    "\n",
    "#X_df = StandardScaler().fit_transform(X_df)\n",
    "if(df2.shape[1]>4):\n",
    "    pca = PCA(n_components=2)\n",
    "    principalComponents = pca.fit_transform(X_df)\n",
    "    principalDf = pd.DataFrame(data = principalComponents,columns = ['PC1', 'PC2'])\n",
    "    finalDf = pd.concat([principalDf, ldf[\"Label\"]], axis = 1)\n",
    "    print()\n",
    "    fig = plt.figure(figsize = (8,8))\n",
    "    ax = fig.add_subplot(1,1,1) \n",
    "    ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "    ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "    til1 = \"HAC (\"+str(filePath)+\") with \"+str(k)+\" clusters\"\n",
    "    ax.set_title(til1, fontsize = 20)\n",
    "    targets = list(set(observed_truth_nparr))\n",
    "    for pt in targets:\n",
    "        indicesToKeep = finalDf['Label'] == pt\n",
    "        ax.scatter(finalDf.loc[indicesToKeep, 'PC1'], finalDf.loc[indicesToKeep, 'PC2'], s = 50)\n",
    "    ax.legend(targets)\n",
    "    ax.grid()\n",
    "\n",
    "elif(df2.shape[1]==4):\n",
    "    dfnew = df3.iloc[:,2:4]\n",
    "    dfnew.columns = ['X','Y']\n",
    "    finalDf = pd.concat([dfnew, ldf[\"Label\"]], axis = 1)\n",
    "    print()\n",
    "    fig = plt.figure(figsize = (8,8))\n",
    "    ax = fig.add_subplot(1,1,1) \n",
    "    ax.set_xlabel('X', fontsize = 15)\n",
    "    ax.set_ylabel('Y', fontsize = 15)\n",
    "    til1 = \"HAC (\"+str(filePath)+\") with \"+str(k)+\" clusters\"\n",
    "    ax.set_title(til1, fontsize = 20)\n",
    "    targets = list(set(observed_truth_nparr))\n",
    "    for pt in targets:\n",
    "        indicesToKeep = finalDf['Label'] == pt\n",
    "        ax.scatter(finalDf.loc[indicesToKeep, 'X'], finalDf.loc[indicesToKeep, 'Y'], s = 50)\n",
    "    ax.legend(targets)\n",
    "    ax.grid()\n",
    "    \n",
    "print(\"Jaccard Coefficient = \" + str(jaccard_coeff))\n",
    "print(\"Rand Index = \" + str(rand_index))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
