{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching the filename, Number of Clusters, Max Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = input(\"Please enter file name: \") #\"cho.txt\"\n",
    "num_clusters = int(input(\"Please enter the number of cluster you would like: \"))\n",
    "max_iter = int(input(\"Please enter the max number of iterations: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Algorithm, Jaccard Co-eff & Rand Index Value Calculation\n",
    "   (Need to provide input for centroids - Scroll Down Please)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(filePath, \"r\")\n",
    "lines = file.readlines()\n",
    "\n",
    "df1 = \"\"\n",
    "# splittng the line into individual data\n",
    "flag1 = 2\n",
    "for line in lines:\n",
    "    if(\" \" in line):\n",
    "        flag1 = 0\n",
    "    elif(\"\\t\" in line):\n",
    "        flag1 = 1\n",
    "    break\n",
    "\n",
    "if(flag1 == 0):\n",
    "    for line in lines:\n",
    "        df1 = pd.read_csv(filePath, sep = ' ', lineterminator = '\\n', header = None)\n",
    "elif(flag1 == 1):\n",
    "    for line in lines:\n",
    "        df1 = pd.read_csv(filePath, sep = '\\t', lineterminator = '\\n', header = None)\n",
    "else:\n",
    "    print(\"Data should be sperated by \\t or single space!\")\n",
    "    \n",
    "df2 = df1.copy()\n",
    "\n",
    "centroids = {}\n",
    "#centroids[0] = \n",
    "clusters = {}\n",
    "old_centroids = {}\n",
    "(rowcount,colcount) = (df2.shape)\n",
    "print(\"Do you want to use default initial centroids (1) or enter your own centroids (2)?\")\n",
    "cent_type = int(input(\"1 for system calculated or 2 for user centroids: \"))\n",
    "for i in range(0,num_clusters):\n",
    "    clusters[i] = [] #[df2.iloc[temp1,0]]\n",
    "\n",
    "if(cent_type==1):\n",
    "    temp1 = 0; step1 = int(rowcount/num_clusters);\n",
    "    for i in range(0,num_clusters):\n",
    "        centroids[i] = df2.iloc[temp1,2:].values\n",
    "        #temp_sse[i] = []\n",
    "        temp1 += step1\n",
    "elif(cent_type==2):\n",
    "    str1 = input(\"Please enter data point (gene) id in a c1,c2,c3 format:\")\n",
    "    str2 = str1.split(\",\")\n",
    "    for i in range(len(str2)):\n",
    "        pt1 = int(str2[i])-1\n",
    "        centroids[i] = df2.iloc[pt1,2:].values\n",
    "    \n",
    "dict1 = {}\n",
    "dict2 = {}\n",
    "for j in range(0,rowcount):\n",
    "    dict1[df2.iloc[j,0]] = df2.iloc[j,2:].values\n",
    "    dict2[df2.iloc[j,0]] = df2.iloc[j,1]\n",
    "    \n",
    "flag = 1\n",
    "iter1 = 0\n",
    "while(flag==1):\n",
    "    #print(\"Iteration Start\")\n",
    "    iter1 +=1\n",
    "    #sse[\"iter\"+str(i+1)] = {}\n",
    "    \n",
    "    old_centroids = centroids.copy()\n",
    "    #sse[\"iter\"+str(i+1)] = {}\n",
    "    for i2 in range(0,num_clusters):\n",
    "        clusters[i2] = []\n",
    "\n",
    "    for i3 in dict1.keys():\n",
    "        dist_temp = 10000\n",
    "        centr_temp = 0\n",
    "        pt1 = dict1[i3]\n",
    "        for j in centroids.keys():\n",
    "            pt2 = centroids[j]\n",
    "            c = pt1-pt2\n",
    "            sum1 = 0\n",
    "            for k in c:\n",
    "                sum1 += (k**2)\n",
    "                #print(sum**(1/2))\n",
    "                #print(c)\n",
    "            sum1 = sum1**(1/2)\n",
    "            if(sum1<dist_temp):\n",
    "                dist_temp = sum1\n",
    "                centr_temp = j\n",
    "        clusters[centr_temp].append(i3)\n",
    "        #temp_sse[centr_temp] = (dist_temp)\n",
    "    #sse[\"iter\"+str(i+1)] = temp_sse\n",
    "    for l in clusters.keys():\n",
    "        list_temp = clusters[l]\n",
    "        s3 = dict1[list_temp[0]]\n",
    "        for m in range(1,len(list_temp)):\n",
    "            s3 = s3 + dict1[list_temp[m]]\n",
    "        centroids[l] = (s3/len(list_temp))\n",
    "        \n",
    "    list1 = []\n",
    "    for cnt in range(0,len(centroids)):\n",
    "        list1.append(np.array_equal(old_centroids[cnt],centroids[cnt]))\n",
    "    if(False in list1):\n",
    "        flag = 1\n",
    "    else:\n",
    "        flag = 0\n",
    "    if(iter1==max_iter):\n",
    "        flag = 0\n",
    "    else:\n",
    "        flag = 1\n",
    "print()\n",
    "print(\"----------------------------------------------------------------------------------------------------\")\n",
    "print(\"Final Centroids -> \"+str(centroids))\n",
    "print(\"Final Clusters -> \"+str(clusters))\n",
    "print(\"----------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "ground_truth = (list(df2.iloc[:,1].values))\n",
    "observed_truth = []\n",
    "for p1 in range(df2.shape[0]):\n",
    "    observed_truth.append(-1)\n",
    "    \n",
    "for i in clusters.keys():\n",
    "    list1 = clusters[i]\n",
    "    for j in list1:\n",
    "        observed_truth[j-1] = (i+1)\n",
    "#print(observed_truth)\n",
    "\n",
    "def cjr(ground_truth,observed_truth):\n",
    "    true_pos = 0\n",
    "    true_neg = 0\n",
    "    false_pos=0\n",
    "    false_neg=0\n",
    "    for i in range(df2.shape[0]):\n",
    "        for j in range(df2.shape[0]):\n",
    "            if ground_truth[i]==ground_truth[j]:\n",
    "                if observed_truth[i]==observed_truth[j]:\n",
    "                    true_pos=true_pos+1\n",
    "                else:\n",
    "                    false_neg=false_neg+1\n",
    "            elif ground_truth[i]!=ground_truth[j]:\n",
    "                if observed_truth[i]==observed_truth[j]:\n",
    "                    false_pos=false_pos+1\n",
    "                else:\n",
    "                    true_neg=true_neg+1\n",
    "    jaccard_coeff = (true_pos)/(true_pos+false_pos+false_neg)\n",
    "    rand_index = (true_pos+true_neg)/(true_pos+true_neg+false_pos+false_neg)\n",
    "    return jaccard_coeff,rand_index\n",
    "\n",
    "jaccard_coeff,rand_index = cjr(ground_truth,observed_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization and Jaccard Co-eff & Rand Index Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "observed_truth_nparr = np.asarray(observed_truth)\n",
    "df3 = df2.copy()\n",
    "X_df = df3.iloc[:,2:].values\n",
    "ldf = pd.DataFrame(observed_truth_nparr,columns=[\"Label\"])\n",
    "\n",
    "\n",
    "X_df = df2.iloc[:,2:].values\n",
    "#X_df = StandardScaler().fit_transform(X_df)\n",
    "if(df2.shape[1]>4):\n",
    "    pca = PCA(n_components=2)\n",
    "    principalComponents = pca.fit_transform(X_df)\n",
    "    principalDf = pd.DataFrame(data = principalComponents,columns = ['PC1', 'PC2'])\n",
    "    finalDf = pd.concat([principalDf, ldf[\"Label\"]], axis = 1)\n",
    "    print()\n",
    "    fig = plt.figure(figsize = (8,8))\n",
    "    ax = fig.add_subplot(1,1,1) \n",
    "    ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "    ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "    til1 = \"K-Means (\"+str(filePath)+\") with \"+str(num_clusters)+\" clusters\"\n",
    "    ax.set_title(til1, fontsize = 20)\n",
    "    targets = list(set(observed_truth_nparr))\n",
    "    for pt in targets:\n",
    "        indicesToKeep = finalDf['Label'] == pt\n",
    "        ax.scatter(finalDf.loc[indicesToKeep, 'PC1'], finalDf.loc[indicesToKeep, 'PC2'], s = 50)\n",
    "    ax.legend(targets)\n",
    "    ax.grid()\n",
    "\n",
    "elif(df2.shape[1]==4):\n",
    "    dfnew = df2.iloc[:,2:4]\n",
    "    dfnew.columns = ['X','Y']\n",
    "    finalDf = pd.concat([dfnew, ldf[\"Label\"]], axis = 1)\n",
    "    print()\n",
    "    fig = plt.figure(figsize = (8,8))\n",
    "    ax = fig.add_subplot(1,1,1) \n",
    "    ax.set_xlabel('X', fontsize = 15)\n",
    "    ax.set_ylabel('Y', fontsize = 15)\n",
    "    til1 = \"K-Means (\"+str(filePath)+\") with \"+str(num_clusters)+\" clusters\"\n",
    "    ax.set_title(til1, fontsize = 20)\n",
    "    targets = list(set(observed_truth_nparr))\n",
    "    for pt in targets:\n",
    "        indicesToKeep = finalDf['Label'] == pt\n",
    "        ax.scatter(finalDf.loc[indicesToKeep, 'X'], finalDf.loc[indicesToKeep, 'Y'], s = 50)\n",
    "    ax.legend(targets)\n",
    "    ax.grid()\n",
    "    \n",
    "print(\"Jaccard Coefficient = \",jaccard_coeff)\n",
    "print(\"Rand Index = \",rand_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
